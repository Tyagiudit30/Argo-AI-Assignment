# -*- coding: utf-8 -*-
"""predict_mental_health

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-KBnP0KYFDgrWNkWMmoT7u932OoVlOHE

**Data Cleaning & Preprocessing**
"""

import pandas as pd

# Load dataset
df = pd.read_csv("survey.csv")  # Change to your dataset filename

# Display basic info
print(df.info())
print(df.head())

"""Check for null values"""

print(df.isnull().sum())

""" Drop irrelevant columns"""

df = df.drop(columns=['Timestamp', 'comments'], errors='ignore')

"""**Handling Missing Values**"""

df['self_employed'].fillna('No', inplace=True)  # Assume 'No' for missing values
df['work_interfere'].fillna('Unknown', inplace=True)  # Replace missing with 'Unknown'

# Dropping 'state' column as it has too many missing values
df.drop(columns=['state'], inplace=True)

"""Fixing Age Column (Removing Outliers)"""

df = df[(df['Age'] >= 18) & (df['Age'] <= 100)]

"""**Handling Categorical Variables**"""

import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder, OneHotEncoder

# Label Encoding for Target Variable ('treatment' - Yes/No to 1/0)
label_encoder = LabelEncoder()
df['treatment'] = label_encoder.fit_transform(df['treatment'])

# One-Hot Encoding for Categorical Features
categorical_columns = ['Gender', 'Country', 'self_employed', 'family_history', 'work_interfere',
                       'no_employees', 'remote_work', 'tech_company', 'benefits', 'care_options',
                       'wellness_program', 'seek_help', 'anonymity', 'leave',
                       'mental_health_consequence', 'phys_health_consequence', 'coworkers',
                       'supervisor', 'mental_health_interview', 'phys_health_interview',
                       'mental_vs_physical', 'obs_consequence']

df_encoded = pd.get_dummies(df, columns=categorical_columns, drop_first=True)

"""**Final Data Summary**"""

print("Cleaned Dataset Shape:", df_encoded.shape)
print(df_encoded.head())

"""# **Step 2: Model Development ðŸš€**"""

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
import joblib

X = df.drop(columns=['treatment'])  # Features
y = df['treatment']  # Target Variable

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

"""Model Training & Evaluation"""

from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.linear_model import LogisticRegression
models = {
        "Random Forest": RandomForestClassifier(random_state=42),
        "XGBoost": XGBClassifier(random_state=42),
        "Logistic Regression": LogisticRegression(random_state=42)
    }

trained_models = {}
for model_name, model in models.items():
  model.fit(X_train, y_train)
  trained_models[model_name] = model

"""**Evaluation Metrics**"""

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

for model_name, model in trained_models.items():
  y_pred = model.predict(X_test)
  accuracy = accuracy_score(y_test, y_pred)
  precision = precision_score(y_test, y_pred, average='weighted')  # Use 'weighted' for multi-class
  recall = recall_score(y_test, y_pred, average='weighted')
  f1 = f1_score(y_test, y_pred, average='weighted')
  print(f"Model: {model_name}")
  print(f"Accuracy: {accuracy:.4f}")
  print(f"Precision: {precision:.4f}")
  print(f"Recall: {recall:.4f}")
  print(f"F1-score: {f1:.4f}")
  print("-" * 20)

"""# ** Developing a Basic UI (Streamlit) and CLI Interface**"""

pip install streamlit

import streamlit as st
import pandas as pd
import joblib  # For loading the trained model

# Save the desired model before loading
# Assuming you want to save the Logistic Regression Model
joblib.dump(trained_models["Logistic Regression"], 'trained_model.pkl')

# Load the trained model
model = joblib.load('trained_model.pkl')  # Replace 'trained_model.pkl' with the actual model filename

# ... (rest of your Streamlit app code) ...